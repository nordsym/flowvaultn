{
  "name": "Prompt Engineer",
  "nodes": [
    {
      "id": "nordsym-brand-header",
      "name": "NordSym Info",
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        0,
        0
      ],
      "parameters": {
        "content": "## üî∑ NordSym AB\n**Verifierad Automation**\n\nüì¶ **K√§lla:** FlowVault.se\nüè∑Ô∏è **Version:** 1.0\nüìß **Support:** support@nordsym.com\n\nüí° **Installation:**\n1. Importera i n8n\n2. Konfigurera credentials\n3. Testa med test-data\n4. Aktivera workflow\n\nüîó **Mer hj√§lp:** nordsym.com",
        "height": 320,
        "width": 300,
        "color": 5
      }
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "typeVersion": 1.1,
      "position": [
        0,
        0
      ],
      "id": "192980eb-7bdb-4ecf-8997-69c86142be27",
      "name": "When chat message received",
      "webhookId": "cab49908-dc42-47fa-9107-4164d15d84c7"
    },
    {
      "parameters": {
        "options": {
          "systemMessage": "You are an intelligent Prompt Engineer specializing in different AI models. Your goal is to help users craft the most effective prompts for their specific needs, considering whether reasoning or non-reasoning models are more appropriate for their tasks.\n\n## Understanding Model Types\n\n### Reasoning Models\n**User Experience:** These models explicitly demonstrate their thinking process, showing step-by-step work before reaching conclusions.\n\n**Key Attributes:**\n- Shows chain-of-thought reasoning\n- Self-corrects during problem solving\n- Excels at complex analytical tasks\n- Higher accuracy for difficult problems\n- Slower response times (500-1500ms)\n- Higher cost per token\n\n**Ideal Applications:**\n- Mathematical problem-solving\n- Code generation and debugging\n- Scientific research analysis\n- Legal document interpretation\n- Tasks requiring explanation of process\n\n### Non-Reasoning Models\n**User Experience:** These models provide direct, fluent responses without showing intermediate steps.\n\n**Key Attributes:**\n- Quick, straightforward responses\n- Optimized for conversational flow\n- More cost-effective\n- Efficient for generative tasks\n- Faster response times (100-300ms)\n\n**Ideal Applications:**\n- Everyday conversations\n- Content creation and writing\n- Simple information retrieval\n- Summarization tasks\n- Creative ideation\n\n## Current Model Classification\n\n### OpenAI\n**Reasoning:** o1, o1-pro, o3-mini\n**Non-Reasoning:** GPT-4o, GPT-4o-mini, GPT-3.5-turbo\n\n### Anthropic\n**Reasoning:** Claude 3.7-Sonnet, Claude 3 Opus\n**Non-Reasoning:** Claude 3.5-Sonnet, Claude 3.5-Haiku, Claude 3 Sonnet\n\n### Google\n**Reasoning:** Gemini 2.5 Pro, Gemini 2.0 Flash Thinking Experimental, Gemini Ultra 2.5\n**Non-Reasoning:** Gemini 2.0 Flash, Gemini 2.0 Pro Experimental, Gemini 2.0 Flash-Lite\n\n## Prompt Engineering Approach\n\n### When Working with Reasoning Models:\n1. **Structure for Deliberate Thinking:**\n   Take your time to think through this problem step by step.\n   1. First, understand what is being asked\n   2. Break down the problem into components\n   3. Work through each component methodically\n   4. Verify your answer before finalizing\n\n2. **Request Explicit Verification:**\n   After providing your initial solution, review it critically.\n   Check for errors in your reasoning or calculations.\n   Consider alternative approaches and explain why your chosen method is optimal.\n\n### When Working with Non-Reasoning Models:\n1. **Direct, Format-Focused Instructions:**\n   Generate [specific content] with the following characteristics:\n   - [Key aspect 1]\n   - [Key aspect 2]\n   - [Tone/style guidance]\n\n2. **Emphasize Desired Output Over Process:**\n   Create a [content type] about [subject].\n   The final output should be [length] and include [specific elements].\n\n## Your Process for Users\n\n1. **Clarify Model Selection:**\n   - If user specifies a model, use it\n   - If not, ask:\n     - \"What task are you trying to accomplish?\"\n     - \"Do you need detailed reasoning or quick responses?\"\n     - \"Do you have a preferred provider (OpenAI, Anthropic, Google)?\"\n\n2. **Match Task to Model Type:**\n   - For complex problem-solving ‚Üí Reasoning models\n   - For creative or conversational tasks ‚Üí Non-Reasoning models\n\n3. **Craft Provider-Specific Prompts:**\n   - Tailor to the exact capabilities of the specified model\n   - Consider unique features (e.g., Claude's XML tags, GPT's JSON mode)\n\n4. **Iterate Based on Feedback:**\n   - Remember previous prompt versions\n   - Incorporate user feedback for improvements\n\nAlways label your final prompt with the specific model it's designed for: \"Optimized for [Provider] [Model]\""
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.7,
      "position": [
        220,
        0
      ],
      "id": "f28c0a0d-8346-4be8-a4b0-762de8d5de04",
      "name": "AI Agent"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-4.5-preview",
          "mode": "list",
          "cachedResultName": "gpt-4.5-preview"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        100,
        280
      ],
      "id": "ac74ae6b-346e-4da0-b2d5-03cbbf1a475f",
      "name": "OpenAI Chat Model",
      "credentials": {
        "openAiApi": {
          "id": "bBtD8KtcEPsOhElY",
          "name": "Prompt Advisers OpenAI Account"
        }
      }
    },
    {
      "parameters": {
        "contextWindowLength": 10
      },
      "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
      "typeVersion": 1.3,
      "position": [
        320,
        340
      ],
      "id": "363c0566-5a44-47c0-9cd1-2954ef78b110",
      "name": "Window Buffer Memory"
    },
    {
      "parameters": {
        "name": "openai_prompt_engineer",
        "description": "Call this tool to generate a prompt specific to OpenAI and any of its GPT models",
        "workflowId": {
          "__rl": true,
          "value": "7vnvCbRQku9Hfm3D",
          "mode": "list",
          "cachedResultName": "My Sub-Workflow 2"
        },
        "workflowInputs": {
          "mappingMode": "defineBelow",
          "value": {},
          "matchingColumns": [],
          "schema": [],
          "attemptToConvertTypes": false,
          "convertFieldsToString": false
        }
      },
      "type": "@n8n/n8n-nodes-langchain.toolWorkflow",
      "typeVersion": 2,
      "position": [
        520,
        340
      ],
      "id": "feab156e-1e7f-43ed-a609-1d93381d9cff",
      "name": "OpenAI Prompt Engineer"
    },
    {
      "parameters": {
        "name": "google_prompt_engineer",
        "description": "Call this tool to generate a prompt specific to Google and any of its gemini models",
        "workflowId": {
          "__rl": true,
          "value": "NvlV0wpPnLABR8Kx",
          "mode": "list",
          "cachedResultName": "Tool Call for Google Prompt Engineer"
        },
        "workflowInputs": {
          "mappingMode": "defineBelow",
          "value": {},
          "matchingColumns": [],
          "schema": [],
          "attemptToConvertTypes": false,
          "convertFieldsToString": false
        }
      },
      "type": "@n8n/n8n-nodes-langchain.toolWorkflow",
      "typeVersion": 2,
      "position": [
        820,
        340
      ],
      "id": "467d7c78-8b06-414a-bc78-be5b7622adb5",
      "name": "Google Prompt Engineer"
    },
    {
      "parameters": {
        "name": "anthropic_claude_prompt_engineer",
        "description": "Call this tool to generate a prompt specific to Anthropic and any of its Claude Models",
        "workflowId": {
          "__rl": true,
          "value": "0zrIEZ7Is3AYfsBy",
          "mode": "list",
          "cachedResultName": "Tool Call for Anthropic Prompt Engineer"
        },
        "workflowInputs": {
          "mappingMode": "defineBelow",
          "value": {},
          "matchingColumns": [],
          "schema": [],
          "attemptToConvertTypes": false,
          "convertFieldsToString": false
        }
      },
      "type": "@n8n/n8n-nodes-langchain.toolWorkflow",
      "typeVersion": 2,
      "position": [
        680,
        340
      ],
      "id": "85ff223c-4b3e-4c94-8fa8-bcb1cc22eb97",
      "name": "Anthropic Prompt Engineer"
    },
    {
      "parameters": {
        "name": "general_prompt_engineer",
        "description": "Call this tool to generate a prompt that is not either OpenAI, Anthropic Claude or Google and any of their models. This tool will generate prompt for other miscellaneous models like DeepSeek, Llama etc.",
        "workflowId": {
          "__rl": true,
          "value": "pBNBcnq6kmmiy1Fi",
          "mode": "list",
          "cachedResultName": "Tool Call for Other Models Prompt Engineer"
        },
        "workflowInputs": {
          "mappingMode": "defineBelow",
          "value": {},
          "matchingColumns": [],
          "schema": [],
          "attemptToConvertTypes": false,
          "convertFieldsToString": false
        }
      },
      "type": "@n8n/n8n-nodes-langchain.toolWorkflow",
      "typeVersion": 2,
      "position": [
        980,
        320
      ],
      "id": "84570633-b78a-41b0-962d-bbbb5961702d",
      "name": "Other/General Prompt Engineer1"
    }
  ],
  "connections": {
    "When chat message received": {
      "main": [
        [
          {
            "node": "AI Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "AI Agent",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Window Buffer Memory": {
      "ai_memory": [
        [
          {
            "node": "AI Agent",
            "type": "ai_memory",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Prompt Engineer": {
      "ai_tool": [
        [
          {
            "node": "AI Agent",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Google Prompt Engineer": {
      "ai_tool": [
        [
          {
            "node": "AI Agent",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Anthropic Prompt Engineer": {
      "ai_tool": [
        [
          {
            "node": "AI Agent",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Other/General Prompt Engineer1": {
      "ai_tool": [
        [
          {
            "node": "AI Agent",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": true,
  "settings": {
    "executionOrder": "v1"
  },
  "versionId": "8cc735c1-a02a-455f-8762-6455f3c28d52",
  "meta": {
    "templateCredsSetupCompleted": true,
    "instanceId": "aaadb797535f05587ee95b776c942a7c3f7a46fd7aa0c9b6a9d64e1e595f8af1",
    "templateCreator": "NordSym AB",
    "templateVersion": "1.0",
    "verified": true,
    "source": "FlowVault.se",
    "contact": "support@nordsym.com",
    "driveFileId": "1NyFafJnrtUi7TOVLscPU_b8RS56M2U2X",
    "brandedAt": "2026-01-01T22:38:40.646Z"
  },
  "id": "hmQXet9chx66zxas",
  "tags": []
}